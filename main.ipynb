{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov  9 13:40:42 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   73C    P0    66W /  70W |  14314MiB / 15109MiB |     99%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            On   | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   80C    P0    64W /  70W |  14314MiB / 15109MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla T4            On   | 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   35C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla T4            On   | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   77C    P0    43W /  70W |   4936MiB / 15109MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      9792      C   ...erver_1_anaconda3/envs/tf230/bin/python 14303MiB |\n",
      "|    1      9792      C   ...erver_1_anaconda3/envs/tf230/bin/python 14303MiB |\n",
      "|    3      2964      C   python                                      4925MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonard/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/tqdm/std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "\n",
    "# from data.datasets import regular_encode, data_generator\n",
    "from data.tokenizer import VnCoreTokenizer\n",
    "# from trainer.model import build_model\n",
    "# from utils import *\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed=1512):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1710\n",
    "MAX_LEN = 296\n",
    "N_HIDDENS = 3\n",
    "BATCH_SIZE = 64\n",
    "N_SPLITS = 5\n",
    "N_EPOCHS = 5\n",
    "DISPLAY = 1  # USE display=1 FOR INTERACTIVE\n",
    "\n",
    "seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vncore_tokenizer = VnCoreTokenizer()\n",
    "# warmup_train_df = pd.read_excel(\"../data/raw_data/warmup_training_dataset.xlsx\", index_col=\"id\")\n",
    "# warmup_test_df = pd.read_excel(\"../data/raw_data/warmup_test_set.xlsx\", index_col=\"id\")\n",
    "\n",
    "# public_train_df = pd.read_csv(\"../data/raw_data/public_train.csv\")\n",
    "# public_test_df = pd.read_csv(\"../data/raw_data/public_test.csv\")\n",
    "\n",
    "# TODO: make use of warmup_test_df\n",
    "# train_df = pd.concat([warmup_train_df, public_train_df]).drop_duplicates()\n",
    "# test_df = public_test_df.copy()\n",
    "# train_df[\"post_message\"].fillna(\"\", inplace=True)\n",
    "\n",
    "# train_df[\"post_message\"] = train_df[\"post_message\"].progress_apply(vncore_tokenizer.tokenize)\n",
    "# test_df[\"post_message\"] = test_df[\"post_message\"].progress_apply(vncore_tokenizer.tokenize)\n",
    "\n",
    "# os.makedirs(\"../data/tokenized_data/\", exist_ok=True)\n",
    "# train_df.to_csv(\"../data/tokenized_data/train.csv\", index=False)\n",
    "# test_df.to_csv(\"../data/tokenized_data/test.csv\", index=False)\n",
    "\n",
    "# train_df = pd.read_csv(\"../data/train_5_folds.csv\")\n",
    "# train_df[\"post_message\"] = train_df[\"post_message\"].astype(str)\n",
    "# train_df[\"post_message\"] = train_df[\"post_message\"].progress_apply(vncore_tokenizer.tokenize)\n",
    "# train_df.to_csv(\"../data/tokenized_data/train_5_folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "train_df = pd.read_csv(\"../data/tokenized_data/train_5_folds.csv\")\n",
    "test_df = pd.read_csv(\"../data/tokenized_data/test.csv\")\n",
    "\n",
    "train_df[\"post_message\"] = train_df[\"post_message\"].astype(str)\n",
    "test_df[\"post_message\"] = test_df[\"post_message\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_len_word = [len(text.split()) for text in train_df.post_message]\n",
    "# test_len_word = [len(text.split()) for text in test_df.post_message]\n",
    "# test_len_char = [len(text) for text in train_df.post_message]\n",
    "# test_len_char = [len(text) for text in test_df.post_message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "def regular_encode(texts, bert_tokenizer, max_len=256):\n",
    "\n",
    "    bert_enc_di = bert_tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        return_token_type_ids=True,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=max_len,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    bert_enc = (\n",
    "        np.array(bert_enc_di[\"input_ids\"]),\n",
    "        np.array(bert_enc_di[\"attention_mask\"]),\n",
    "        np.array(bert_enc_di[\"token_type_ids\"]),\n",
    "    )\n",
    "    return bert_enc\n",
    "\n",
    "\n",
    "def data_generator(train_df, val_df, bert_tokenizer, max_len, batch_size=32):\n",
    "\n",
    "    X_train = regular_encode(train_df[\"post_message\"].values, bert_tokenizer, max_len)\n",
    "    # y_train = tf.keras.utils.to_categorical(train_df['Label'].values, num_classes=2)\n",
    "    y_train = train_df[\"label\"].values\n",
    "    X_val = regular_encode(val_df[\"post_message\"].values, bert_tokenizer, max_len)\n",
    "    # y_val = tf.keras.utils.to_categorical(val_df['Label'].values, num_classes=2)\n",
    "    y_val = val_df[\"label\"].values\n",
    "\n",
    "    train_dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "        .repeat()\n",
    "        .shuffle(1024)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(AUTO)\n",
    "    )\n",
    "\n",
    "    valid_dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "        .batch(batch_size)\n",
    "        .cache()\n",
    "        .prefetch(AUTO)\n",
    "    )\n",
    "\n",
    "    return train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(bert_model_name_or_path=\"vinai/phobert-base\", max_len=384, n_hiddens=4):\n",
    "    bert_model = TFAutoModel.from_pretrained(bert_model_name_or_path)\n",
    "\n",
    "    bert_input_word_ids = tf.keras.layers.Input(\n",
    "        shape=(max_len,), dtype=tf.int32, name=\"bert_input_id\"\n",
    "    )\n",
    "    bert_attention_mask = tf.keras.layers.Input(\n",
    "        shape=(max_len,), dtype=tf.int32, name=\"bert_attention_mask\"\n",
    "    )\n",
    "    bert_token_type_ids = tf.keras.layers.Input(\n",
    "        shape=(max_len,), dtype=tf.int32, name=\"bert_token_type_ids\"\n",
    "    )\n",
    "\n",
    "    bert_sequence_output = bert_model(\n",
    "        bert_input_word_ids,\n",
    "        attention_mask=bert_attention_mask,\n",
    "        token_type_ids=bert_token_type_ids,\n",
    "        output_hidden_states=True,\n",
    "        output_attentions=True,\n",
    "        \n",
    "    )\n",
    "\n",
    "    # print(len(bert_sequence_output)) # 4\n",
    "\n",
    "    # print(bert_sequence_output[0].shape) # (None, max_len, 768)\n",
    "\n",
    "    # print(bert_sequence_output[1].shape) # (None, 768)\n",
    "    # print(len(bert_sequence_output[2])) # 13\n",
    "    # print(bert_sequence_output[2][0].shape) # (None, max_len, 768)\n",
    "    # print(len(bert_sequence_output[3])) # 12\n",
    "    # print(bert_sequence_output[3][0].shape) # (None, 12, None, max_len)\n",
    "\n",
    "    # TODO: get bert embedding\n",
    "\n",
    "    if n_hiddens == -1:  # get [CLS] token embedding only\n",
    "        # print(\"Get pooler output of shape (batch_size, hidden_size)\")\n",
    "        bert_sequence_output = bert_sequence_output[0][:, 0, :]\n",
    "    else:  # concatenate n_hiddens final layer\n",
    "        # print(f\"Concatenate {n_hiddens} hidden_states of shape (batch_size, hidden_size)\")\n",
    "        bert_sequence_output = tf.concat(\n",
    "            [bert_sequence_output[2][-i] for i in range(n_hiddens)], axis=-1)\n",
    "\n",
    "    # print(\"bert_sequence_output shape\", bert_sequence_output.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    out = tf.keras.layers.Flatten()(bert_sequence_output)\n",
    "    out = tf.keras.layers.Dense(1, activation=\"sigmoid\")(out)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[\n",
    "            bert_input_word_ids,\n",
    "            bert_attention_mask,\n",
    "            bert_token_type_ids,  # bert input\n",
    "        ],\n",
    "        outputs=out,\n",
    "    )\n",
    "    model.compile(\n",
    "        tf.keras.optimizers.Adam(lr=5e-5),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[tf.keras.metrics.AUC()],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at /home/leonard/leonard/vlsp/ReINTEL/pretrained_phobert-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at /home/leonard/leonard/vlsp/ReINTEL/pretrained_phobert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "bert_input_id (InputLayer)      [(None, 296)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_attention_mask (InputLayer [(None, 296)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_token_type_ids (InputLayer [(None, 296)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_roberta_model (TFRobertaMode ((None, 296, 768), ( 134998272   bert_input_id[0][0]              \n",
      "                                                                 bert_attention_mask[0][0]        \n",
      "                                                                 bert_token_type_ids[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 296, 2304)]  0           tf_roberta_model[0][2]           \n",
      "                                                                 tf_roberta_model[0][14]          \n",
      "                                                                 tf_roberta_model[0][13]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 681984)       0           tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            681985      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 135,680,257\n",
      "Trainable params: 135,680,257\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert = \"/home/leonard/leonard/vlsp/ReINTEL/pretrained_phobert-base\"\n",
    "# bert = 'vinai/phobert-base'\n",
    "\n",
    "model = build_model(bert, max_len=MAX_LEN, n_hiddens=N_HIDDENS)\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert)\n",
    "\n",
    "model.summary()\n",
    "exp = f'phobert_{MAX_LEN}_len_{N_SPLITS}_folds_{N_HIDDENS}_hidden_states'\n",
    "\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "output_dir = f'../outputs/{exp}_models'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model,\n",
    "                        #   show_shapes=False,\n",
    "                        #   show_layer_names=True,\n",
    "                        #   rankdir='TB', \n",
    "                        #   expand_nested=False,\n",
    "                          dpi=50\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    return 3e-5*0.2**epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "FOLD: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at /home/leonard/leonard/vlsp/ReINTEL/pretrained_phobert-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at /home/leonard/leonard/vlsp/ReINTEL/pretrained_phobert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
      "/home/leonard/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2029: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From /home/leonard/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "INFO:tensorflow:batch_all_reduce: 196 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 3 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "INFO:tensorflow:batch_all_reduce: 196 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 3 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3500 - auc: 0.8458\n",
      "Epoch 00001: val_auc improved from -inf to 0.92099, saving model to ../outputs/phobert_296_len_5_folds_3_hidden_states_models/Fold_1_1710.h5\n",
      "67/67 [==============================] - 83s 1s/step - loss: 0.3500 - auc: 0.8458 - val_loss: 0.2737 - val_auc: 0.9210\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2374 - auc: 0.9361\n",
      "Epoch 00002: val_auc improved from 0.92099 to 0.93233, saving model to ../outputs/phobert_296_len_5_folds_3_hidden_states_models/Fold_1_1710.h5\n",
      "67/67 [==============================] - 72s 1s/step - loss: 0.2374 - auc: 0.9361 - val_loss: 0.3033 - val_auc: 0.9323\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1343 - auc: 0.9804\n",
      "Epoch 00003: val_auc improved from 0.93233 to 0.93642, saving model to ../outputs/phobert_296_len_5_folds_3_hidden_states_models/Fold_1_1710.h5\n",
      "67/67 [==============================] - 72s 1s/step - loss: 0.1343 - auc: 0.9804 - val_loss: 0.2904 - val_auc: 0.9364\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1678 - auc: 0.9710\n",
      "Epoch 00004: val_auc did not improve from 0.93642\n",
      "67/67 [==============================] - 70s 1s/step - loss: 0.1678 - auc: 0.9710 - val_loss: 0.2730 - val_auc: 0.9355\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1286 - auc: 0.9816\n",
      "Epoch 00005: val_auc did not improve from 0.93642\n",
      "67/67 [==============================] - 69s 1s/step - loss: 0.1286 - auc: 0.9816 - val_loss: 0.2755 - val_auc: 0.9353\n",
      "****************************************************************************************************\n",
      "FOLD: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at /home/leonard/leonard/vlsp/ReINTEL/pretrained_phobert-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at /home/leonard/leonard/vlsp/ReINTEL/pretrained_phobert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
      "/home/leonard/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2029: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3540 - auc: 0.8316\n",
      "Epoch 00001: val_auc improved from -inf to 0.93222, saving model to ../outputs/phobert_296_len_5_folds_3_hidden_states_models/Fold_2_1710.h5\n",
      "65/65 [==============================] - 82s 1s/step - loss: 0.3540 - auc: 0.8316 - val_loss: 0.2915 - val_auc: 0.9322\n",
      "Epoch 2/5\n",
      "21/65 [========>.....................] - ETA: 39s - loss: 0.2297 - auc: 0.9264"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-40353c92d469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m                    ],\n\u001b[1;32m     38\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     )\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/leonard/ai_server_1_anaconda3/envs/tf230/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for fold, (idxT, idxV) in enumerate(kf.split(train_df)):\n",
    "for fold in sorted(train_df[\"fold\"].unique()):\n",
    "    print('*'*100)\n",
    "    print(f'FOLD: {fold+1}/{N_SPLITS}')\n",
    "    \n",
    "    K.clear_session()\n",
    "    with strategy.scope():\n",
    "        model = build_model(bert, max_len=MAX_LEN, n_hiddens=N_HIDDENS)\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "    model_dir = os.path.join(output_dir, f'Fold_{fold+1}_{SEED}.h5')\n",
    "\n",
    "    sv = tf.keras.callbacks.ModelCheckpoint(model_dir,\n",
    "                                            monitor='val_auc',\n",
    "                                            verbose=1,\n",
    "                                            save_best_only=True,\n",
    "                                            save_weights_only=True,\n",
    "                                            mode='max',\n",
    "                                            save_freq='epoch')\n",
    "    \n",
    "#     train_df_ = train_df.iloc[idxT]\n",
    "#     val_df_ = train_df.iloc[idxV]\n",
    "    train_df_ = train_df[train_df[\"fold\"]!=fold]\n",
    "    val_df_ = train_df[train_df[\"fold\"]==fold]\n",
    "\n",
    "    train_dataset, valid_dataset = data_generator(train_df_, val_df_, bert_tokenizer, max_len=MAX_LEN)\n",
    "\n",
    "    n_steps = train_df_.shape[0] // BATCH_SIZE\n",
    "    train_history = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=n_steps,\n",
    "\n",
    "        callbacks=[sv,\n",
    "                   reduce_lr,\n",
    "                   # tb\n",
    "                   ],\n",
    "        validation_data=valid_dataset,\n",
    "        epochs=N_EPOCHS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = regular_encode(test_df['post_message'].values, bert_tokenizer, maxlen=MAX_LEN)\n",
    "y_test = np.zeros((len(test_df), 1))\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((X_test, y_test))\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(bert, max_len=MAX_LEN, n_hiddens=N_HIDDENS)\n",
    "preds = []\n",
    "\n",
    "for i, file_name in enumerate(os.listdir(output_dir)):\n",
    "    print('_'*80)\n",
    "\n",
    "    K.clear_session()\n",
    "    model_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    print(f'Inferencing with model from: {model_path}')\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    pred = model.predict(test_dataset,\n",
    "                         batch_size=128,\n",
    "                         verbose=DISPLAY)\n",
    "    # print(pred[])\n",
    "    preds.append(pred)\n",
    "\n",
    "\n",
    "preds = np.mean(preds, axis=0)\n",
    "\n",
    "test_df[\"prediction\"] = preds\n",
    "\n",
    "test_df[\"prediction\"].to_csv(f\"{exp}.csv\", header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
